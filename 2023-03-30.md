# Deep_Learning
## 최적화
### 베이즈 정리
P(B∣A)= P(A∣B)P(B) / P(A)
베이즈 정리를 활용하여 B일 때, A일 확률을 알 경우, A일 때 B의 확률은 계산할 수 있음

즉, 우도와 사전확률을 알면 사후확률을 계산할 수 있음

- 한계
하나의 case에 대해 사전확률이 너무 크면 예측 task 자체가 의미 없어질 수 있음

예시: 여자, 남자의 키에 대한 우도를 알고있을 경우, 키가 180인 사람의 성별을 예측한다고 하자.

보통 사후확률 예측 결과로는 남자를 기대할 것, 그러나 만약 키에 대한 조사를 진행했을 때, 여자의 사전확률이 0.99, 남자의 사전확률이 0.01이었다면 사후확률 결과 예측는 여자로 예측 될 것

### MLE(Maximum Likelihood Estimator)
최대 우도법: 매개변수 세타를 모르는 상황에서, 우도가 최대가 되는 세타를 추정하는 방법

- 최대 로그 우도 추정 방법: 우도 추정 방법은 확률은 계속 곱하기 때문에 수치문제 발생(수치문제: 확률을 계속 곱하게 되면 1보다 작은 값을 계속 곱하기 때문에 너무 작은 값이 되고,
 정밀도를 넘어서서 0에 근접하게 되면 0으로 수렴 됨)
 
 => log 표현으로 바꿔서 확률의 곱을 덧셈으로 바꾸서 계산하는 방법
 
 ### 정보이론
 정보: 확률이 작을 수록, 즉 알지 못하는 것일 수록 정보량이 큼
 
 엔트로피가 낮다 = 특정 사건이 높은 확률을 가지고 있다
 엔트로피가 높다 = 특성 사건의 확률이 낮다
 
 엔트로피 = 불확실성 = 무질서도
 
 ex)
 
 4가지 사건의 발생 확률이 모두 25% => 엔트로피 최대, 불확실성 높음
 
 4가지 상황 중 하나의 확률이 97%, 나머지가 1% => 엔트로피 낮음, 불확실성 낮음
 
 - KL 다이버전스: 두 분포의 거리를 나타내는 값, 두 분포가 떨어지면 KL 다이버전스 값 증가
 
## 최적화
### analytic vs numerical
- analytic method: 미분을 통해 한 번에 최저점 계산
- numerical method: 미분을 통한 계산이 어려운 경우, 점진적인 방식을 통해 최저점 탐색
