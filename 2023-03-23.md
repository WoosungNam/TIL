# Deep_Learning Basic
## supervised Learning vs unsupervised Learning vs reingorcement Learning
- 지도학습: 특징 벡터 x와 목표값 y 모두 주어진 경우, 회귀와 분류 문제가 존재
- 비지도학습: 특징 벡터 x만 주어지고 목표값은 주어지지 않은 경우, 군집화 작업, 밀도 추정, 특징 공간 변환 가능

ex) 유튜브 추천 알고리즘이 대표적인 비지도 학습을 활용한 경우
- 강화학습: 목표값이 결과에 대한 보상의 형태로 제공됨

ex) 바둑에서 수를 두는 행위가 sample인데, 게임을 이기면 +1점, 지면 -1점 => 높은 점수를 부여하는 행위를 하게끔 학습

agent와 environment 객체 사이에서 reward를 통해 agent의 행동을 학습 시킴

- 준지도학습: 특정 data에 대해서만 label이 존재, 나머지는 label이 존재하지 않은 경우

## 온라인 학습 vs 오프라인 학습
온라인 학습은 오프라인 학습과는 다르게 인터넷 등에서 추가로 발생하는 샘플을 가지고 점증적으로 학습을 진행

## 결정론적 학습 vs 스토캐스틱 학습
-결정론적 학습: 동일한 데이터로 학습을 진행하면 매번 동일한 예측기가 생성
-스토캐스틱 학습: 학습 과정에서 난수를 사용해서 같은 데이터로 학습을 시도해도 다른 예측기가 생성되는 학습

ex) 직선을 예상하는 선형회귀 모델은 스토캐스틱 학습, 처음 시작시 파라미터를 난수로 생성했기에 시작 위치가 달라지고, 근처의 목적함수 값이 가장 낮은 곳으로 수렴

=> 매 시행마다 수렴되는 위치가 변경됨

-앙상블: 스토캐스틱 방식을 활용, 시행 시마다 다른 예측기가 만들어지므로 한 번만 학습하지 않고, 여러 번 학습을 통해 다른 예측기를 만들고, 만들어진 모든 예측기들을 활용해 더 좋은 모델을 생성

## 분별 모델 vs 생성 모델
- 분별 모델: x가 주어졌을 때, y를 예측하는 것에 대한 확률을 학습
- 생성 모델: y가 주어졌을 때, x를 생성하는 모델

즉 두 모델은 역방향의 모델

## vector
### tensor
3차원 이상의 구조를 가진 숫자 배열

ex) 이미지는 R, G, B의 3차원 배열을 가지는 tensor, 동영상은 R, G, B에 frame까지 가지는 4차원 tensor

### norm
(x,y)의 거리를 측정하는 경우,
- 1차 놈: x + y
- 2차 놈: (x^2 + y^2)^1/2
- 3차 놈: (x^3 + y^3)^1/3
과 같은 형식(일반적으로 말하는 거리는 2차 놈에 해당)

### cosine_similarity
코사인 유사도: a와 b벡터를 내적할 때, 각가을 유닛벡터로 만들고 내적시킨 값, 즉 두 벡터를 정규화하고 내적

코사인 유사도는 두 벡터의 유사도를 의미함

### perceptron
d개의 입력특징이 주어졌을 때, 각각에 가중치를 곱하고 모두 더해 값 a를 구한뒤, a의 값이 threshold T보다 크면 1로 결정, 작으면 -1로 결정하는 방식과 같이 동작하는 분류 모델

### vector spave
벡터공간: 벡터가 존재하는 공간으로, 기저벡터들의 선형결합으로 만들어짐

정규직교 기저 벡터: 정규(noraml), 직교(orthogonal), 기저(basic)을 만족하는 벡터, 즉 길이가 1이고 수직을 이루는 벡터가 정규직교 벡터

### inverse matrix
가역행렬이 되기 위한 필요충분 조건
1. 특이행렬(singular matrix)가 아니어야 함, 즉 행렬식이 0이 아니어야 함
2. 정사각행렬이어야 함
3. 모든 행이 최대 계수를 가짐 = 모든 행이 선형독립 = 모든 열이 선형독립
4. 어떤 고윳값도 0이 아니어야 함

### determinant
행렬식의 기하학적 의미는 만약 2개의 벡터라고 한다면 2개의 벡터가 이루는 평행사변형의 넓이
만약 3개의 벡터라고 한다면 3개의 벡터가 이루는 평행사각기둥의 부피
